{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = []\n",
    "a.append([1,1,1,1])\n",
    "a.append([1,1,1,1])\n",
    "a.append([1,1,1,1])\n",
    "a.append([1,1,1,1])\n",
    "a = np.array(a)\n",
    "print(np.mean(a,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python\n",
    "# coding: utf-8\n",
    "# rdkit 绘制分子【可视化分子】\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "\n",
    "opts = DrawingOptions()\n",
    "m = Chem.MolFromSmiles('C=C(N)COC1=CC(C)=C(C(=C)C)C(C)=C1Br')\n",
    "opts.includeAtomNumbers=True\n",
    "opts.bondLineWidth=2.8\n",
    "draw = Draw.MolToImage(m, options=opts)\n",
    "draw.save('./mol3.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new:emb.weight, old:emb.weight\n",
      "new:emb.bias, old:emb.bias\n",
      "new:d_gcn1.weight, old:d_gcn11.weight\n",
      "new:d_gcn2.weight, old:d_gcn21.weight\n",
      "new:d_gcn3.weight, old:d_gcn3.weight\n",
      "new:g_gcn1.weight, old:g_gcn1.weight\n",
      "new:g_gcn2.weight, old:g_gcn2.weight\n",
      "new:g_gcn3.weight, old:g_gcn3.weight\n",
      "new:linear_stop1.weight, old:linear_stop1.weight\n",
      "new:linear_stop2.weight, old:linear_stop2.weight\n",
      "new:linear_stop2.bias, old:linear_stop2.bias\n",
      "new:linear_first1.weight, old:linear_first1.weight\n",
      "new:linear_first1.bias, old:linear_first1.bias\n",
      "new:linear_first2.weight, old:linear_first2.weight\n",
      "new:linear_first2.bias, old:linear_first2.bias\n",
      "new:linear_second1.weight, old:linear_second1.weight\n",
      "new:linear_second1.bias, old:linear_second1.bias\n",
      "new:linear_second2.weight, old:linear_second2.weight\n",
      "new:linear_second2.bias, old:linear_second2.bias\n",
      "new:linear_edge1.weight, old:linear_edge1.weight\n",
      "new:linear_edge1.bias, old:linear_edge1.bias\n",
      "new:linear_edge2.weight, old:linear_edge2.weight\n",
      "new:linear_edge2.bias, old:linear_edge2.bias\n",
      "new:value1.weight, old:value1.weight\n",
      "new:value2.weight, old:value2.weight\n",
      "new:value2.bias, old:value2.bias\n",
      "<generator object Module.parameters at 0x000001AE634B56D0>\n",
      "<generator object Module.parameters at 0x000001AE634B56D0>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import gym_molecule\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class Nopo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Nopo, self).__init__()\n",
    "        self.pi = GCNPolicy()\n",
    "        self.old_pi = GCNPolicy()\n",
    "\n",
    "class GCNPolicy(nn.Module):\n",
    "    def __init__(self, out_channels=64, stop_shift=-3, atom_type_num=9,in_channels=9, edge_type=3):\n",
    "        super(GCNPolicy, self).__init__()\n",
    "        self.stop_shift = stop_shift\n",
    "        self.atom_type_num = atom_type_num\n",
    "        self.emb = nn.Linear(in_channels, 8)\n",
    "        self.ac_real = np.array([])\n",
    "        \n",
    "        self.d_gcn1 = nn.Linear(8, out_channels, bias=False)\n",
    "        self.d_gcn2 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.d_gcn3 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        \n",
    "        self.g_gcn1 = nn.Linear(8, out_channels, bias=False)\n",
    "        self.g_gcn2 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.g_gcn3 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        \n",
    "        self.linear_stop1 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.linear_stop2 = nn.Linear(out_channels, 2)\n",
    "\n",
    "        self.linear_first1 = nn.Linear(out_channels, out_channels)\n",
    "        self.linear_first2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "        self.linear_second1 = nn.Linear(2*out_channels, out_channels)\n",
    "        self.linear_second2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "        self.linear_edge1 = nn.Linear(2*out_channels, out_channels)\n",
    "        self.linear_edge2 = nn.Linear(out_channels, edge_type)\n",
    "\n",
    "        self.value1 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.value2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def mask_emb_len(self, emb_node, mask_len, fill):\n",
    "        '''\n",
    "        在结点嵌入emb中，只留前mask_len个结点的特征，\n",
    "        将之后其他结点的特征全部置为fill\n",
    "        emb_node: Tensor\n",
    "        mask_len: int\n",
    "        fill: int\n",
    "        '''\n",
    "        node_num = emb_node.shape[-2]\n",
    "        v_size = mask_len.tile((1,node_num))\n",
    "        seq_range = torch.arange(0, node_num).tile(v_size.shape[0],1)\n",
    "        mask = seq_range>=v_size\n",
    "        mask = mask.unsqueeze(-1).expand(emb_node.shape)\n",
    "        return emb_node.masked_fill_(mask,fill)\n",
    "\n",
    "    def set_ac_real(self, ac_real):\n",
    "        self.ac_real = ac_real\n",
    "\n",
    "    def forward(self, adj, node):\n",
    "        stop_shift = self.stop_shift\n",
    "        atom_type_num = self.atom_type_num\n",
    "        self.adj = torch.Tensor(adj)\n",
    "        self.node = torch.Tensor(node)\n",
    "        if self.adj.dim() == 3:\n",
    "            self.adj = self.adj.unsqueeze(0)\n",
    "        if self.node.dim() == 3:\n",
    "            self.node = self.node.unsqueeze(0)\n",
    "\n",
    "        ob_node = self.emb(self.node)\n",
    "        emb_node = F.relu(self.g_gcn1(torch.einsum(\"bijk,bikl->bijl\",self.adj,ob_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1).unsqueeze(1)\n",
    "        emb_node = F.relu(self.g_gcn2(torch.einsum(\"bijk,bikl->bijl\",self.adj,emb_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1).unsqueeze(1)\n",
    "        emb_node = F.relu(self.g_gcn3(torch.einsum(\"bijk,bikl->bijl\",self.adj,emb_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1)\n",
    "        #(B,n,n) * (B,n,f) -> (B,n,f)\n",
    "        \n",
    "        seq_range = torch.arange(0, emb_node.shape[-2])\n",
    "        ### 1.计算ob中有效node的个数\n",
    "        ob_len = torch.sum(torch.BoolTensor(torch.sum(self.node,-1)>0),-1)\n",
    "        ob_len_first = ob_len - atom_type_num\n",
    "        emb_node = self.mask_emb_len(emb_node, ob_len, 0)\n",
    "\n",
    "        ### 2.预测停止动作\n",
    "        emb_stop = F.relu(self.linear_stop1(emb_node))\n",
    "        self.logits_stop = torch.sum(emb_stop,1) #(B,1,f)\n",
    "        self.logits_stop = self.linear_stop2(self.logits_stop) #(B,1,2)\n",
    "        \n",
    "        # 分类分布中认为1是停止，但不能让它停止的过早，导致生成分子过简单 stop_shift一个负数\n",
    "        stop_shift = torch.Tensor([[0, stop_shift]])\n",
    "        pd_stop = D.Categorical(logits=self.logits_stop + stop_shift)\n",
    "        ac_stop = pd_stop.sample() #(B,1)\n",
    "        ac_stop = ac_stop.unsqueeze(-1)\n",
    "\n",
    "        ### 3.1 选第一个有效点(已在分子图中的)\n",
    "        self.logits_first = F.relu(self.linear_first1(emb_node)) #(B,n,f)\n",
    "        self.logits_first = self.linear_first2(emb_node).squeeze(-1) #(B,n)\n",
    "        # 保证选不到无效点\n",
    "        self.logits_first = self.logits_first.masked_fill(seq_range.expand(self.logits_first.shape)>=ob_len_first.expand(self.logits_first.shape),-10000)\n",
    "        pd_first = D.Categorical(logits=self.logits_first)\n",
    "        ac_first = pd_first.sample()\n",
    "        ac_first = ac_first.unsqueeze(-1) #(B,1)\n",
    "        # 只留选中结点的emb (B,f)\n",
    "        emb_first = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_first.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2)      \n",
    "        # 专家网络ground truth action\n",
    "        if self.ac_real.size>0:\n",
    "            ac_first_real = torch.Tensor(self.ac_real[:,0])\n",
    "            ac_first_real = ac_first_real.unsqueeze(-1)\n",
    "            emb_first_real = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_first_real.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2) \n",
    "\n",
    "        ### 3.2 选第二个点\n",
    "        emb_cat = torch.cat((emb_first.unsqueeze(-2).expand(emb_node.shape),emb_node), -1) #(B,n,2f)\n",
    "        self.logits_second = F.relu(self.linear_second1(emb_cat)) #(B,n,f)\n",
    "        self.logits_second = self.linear_second2(self.logits_second) #(B,n,1)\n",
    "        self.logits_second = self.logits_second.squeeze(-1)\n",
    "        self.logits_second = self.logits_second.masked_fill(ac_first.expand(self.logits_second.shape) == seq_range.unsqueeze(0).expand(self.logits_second.shape), -10000)\n",
    "        self.logits_second = self.logits_second.masked_fill(seq_range.expand(self.logits_second.shape)>=ob_len.expand(self.logits_second.shape),-10000)\n",
    "\n",
    "        pd_second = D.Categorical(logits=self.logits_second)\n",
    "        ac_second = pd_second.sample()\n",
    "        ac_second = ac_second.unsqueeze(-1)\n",
    "        # 只留选中结点的emb (B,f)\n",
    "        emb_second = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_second.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2) \n",
    "\n",
    "        # groundtruth\n",
    "        if self.ac_real.size>0:\n",
    "            emb_cat = torch.cat((emb_first_real.unsqueeze(-2).expand(emb_node.shape),emb_node), -1) #(B,n,2f)\n",
    "            self.logits_second_real = F.relu(self.linear_second1(emb_cat))\n",
    "            self.logits_second_real = self.linear_second2(self.logits_second_real).squeeze(-1)\n",
    "            ac_second_real = torch.Tensor(self.ac_real[:,1])\n",
    "            ac_second_real = ac_second_real.unsqueeze(-1)\n",
    "            emb_second_real = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_second_real.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2)\n",
    "\n",
    "        ### 3.3 预测边类型\n",
    "        emb_cat = torch.cat((emb_first,emb_second),-1) #(B,2f)\n",
    "        self.logits_edge = F.relu(self.linear_edge1(emb_cat)) #(B,f)\n",
    "        self.logits_edge = self.linear_edge2(self.logits_edge) #(B,e)\n",
    "        pd_edge = D.Categorical(logits = self.logits_edge)\n",
    "        ac_edge = pd_edge.sample()\n",
    "        ac_edge = ac_edge.unsqueeze(-1)\n",
    "\n",
    "        #groundtruth\n",
    "        if self.ac_real.size>0:\n",
    "            emb_cat = torch.cat((emb_first_real, emb_second_real), -1)\n",
    "            self.logits_edge_real = F.relu(self.linear_edge1(emb_cat))\n",
    "            self.logits_edge_real = self.linear_edge2(self.logits_edge_real)\n",
    "        \n",
    "        ### 4. 预测状态价值\n",
    "        self.vpred = F.relu(self.value1(emb_node))\n",
    "        self.vpred = torch.max(self.vpred,1).values #(B,1,f)\n",
    "        self.vpred = self.value2(self.vpred)\n",
    "\n",
    "        self.ac = torch.cat((ac_first,ac_second,ac_edge,ac_stop),-1)\n",
    "        self.pd = None\n",
    "        if self.ac_real.size>0:\n",
    "            self.pd = {\"first\": D.Categorical(logits=self.logits_first), \"second\": D.Categorical(logits=self.logits_second_real), \n",
    "                        \"edge\": D.Categorical(logits=self.logits_edge_real), \"stop\": D.Categorical(logits=self.logits_stop)}\n",
    "            self.ac_real = np.array([])\n",
    "        return self.ac, self.vpred\n",
    "\n",
    "    def logp(self, ac):\n",
    "        ac = torch.LongTensor(ac)\n",
    "        if self.pd != None: \n",
    "            return self.pd[\"first\"].log_prob(ac[:,0]) + self.pd[\"second\"].log_prob(ac[:,1])\\\n",
    "                 + self.pd[\"edge\"].log_prob(ac[:,2]) + self.pd[\"stop\"].log_prob(ac[:,3])\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def entorpy(self):\n",
    "        result = None\n",
    "        if self.pd != None:\n",
    "            result =  self.pd[\"first\"].entropy() + self.pd[\"second\"].entropy()\\\n",
    "                 + self.pd[\"edge\"].entropy() + self.pd[\"stop\"].entropy()\n",
    "        return result\n",
    "\n",
    "    def kl(self, other_pd):\n",
    "        result = None\n",
    "        if self.pd != None and other_pd != None:\n",
    "            result = D.kl_divergence(self.pd[\"first\"], other_pd[\"first\"]) + D.kl_divergence(self.pd[\"second\"], other_pd[\"second\"])\\\n",
    "                + D.kl_divergence(self.pd[\"edge\"], other_pd[\"edge\"]) + D.kl_divergence(self.pd[\"stop\"], other_pd[\"stop\"])\n",
    "        return result\n",
    "    \n",
    "class GCNPolicyold(nn.Module):\n",
    "    def __init__(self, out_channels=64, stop_shift=-3, atom_type_num=9,in_channels=9, edge_type=3):\n",
    "        super(GCNPolicyold, self).__init__()\n",
    "        self.stop_shift = stop_shift\n",
    "        self.atom_type_num = atom_type_num\n",
    "        self.emb = nn.Linear(in_channels, 8)\n",
    "        self.ac_real = np.array([])\n",
    "        \n",
    "        self.d_gcn11 = nn.Linear(8, out_channels, bias=False)\n",
    "        self.d_gcn21 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.d_gcn3 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        \n",
    "        self.g_gcn1 = nn.Linear(8, out_channels, bias=False)\n",
    "        self.g_gcn2 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.g_gcn3 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        \n",
    "        self.linear_stop1 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.linear_stop2 = nn.Linear(out_channels, 2)\n",
    "\n",
    "        self.linear_first1 = nn.Linear(out_channels, out_channels)\n",
    "        self.linear_first2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "        self.linear_second1 = nn.Linear(2*out_channels, out_channels)\n",
    "        self.linear_second2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "        self.linear_edge1 = nn.Linear(2*out_channels, out_channels)\n",
    "        self.linear_edge2 = nn.Linear(out_channels, edge_type)\n",
    "\n",
    "        self.value1 = nn.Linear(out_channels, out_channels, bias=False)\n",
    "        self.value2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def mask_emb_len(self, emb_node, mask_len, fill):\n",
    "        '''\n",
    "        在结点嵌入emb中，只留前mask_len个结点的特征，\n",
    "        将之后其他结点的特征全部置为fill\n",
    "        emb_node: Tensor\n",
    "        mask_len: int\n",
    "        fill: int\n",
    "        '''\n",
    "        node_num = emb_node.shape[-2]\n",
    "        v_size = mask_len.tile((1,node_num))\n",
    "        seq_range = torch.arange(0, node_num).tile(v_size.shape[0],1)\n",
    "        mask = seq_range>=v_size\n",
    "        mask = mask.unsqueeze(-1).expand(emb_node.shape)\n",
    "        return emb_node.masked_fill_(mask,fill)\n",
    "\n",
    "    def set_ac_real(self, ac_real):\n",
    "        self.ac_real = ac_real\n",
    "\n",
    "    def forward(self, adj, node):\n",
    "        stop_shift = self.stop_shift\n",
    "        atom_type_num = self.atom_type_num\n",
    "        self.adj = torch.Tensor(adj)\n",
    "        self.node = torch.Tensor(node)\n",
    "        if self.adj.dim() == 3:\n",
    "            self.adj = self.adj.unsqueeze(0)\n",
    "        if self.node.dim() == 3:\n",
    "            self.node = self.node.unsqueeze(0)\n",
    "\n",
    "        ob_node = self.emb(self.node)\n",
    "        emb_node = F.relu(self.g_gcn1(torch.einsum(\"bijk,bikl->bijl\",self.adj,ob_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1).unsqueeze(1)\n",
    "        emb_node = F.relu(self.g_gcn2(torch.einsum(\"bijk,bikl->bijl\",self.adj,emb_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1).unsqueeze(1)\n",
    "        emb_node = F.relu(self.g_gcn3(torch.einsum(\"bijk,bikl->bijl\",self.adj,emb_node.tile((1,self.adj.shape[1],1,1)))))\n",
    "        emb_node = torch.mean(emb_node,1)\n",
    "        #(B,n,n) * (B,n,f) -> (B,n,f)\n",
    "        \n",
    "        seq_range = torch.arange(0, emb_node.shape[-2])\n",
    "        ### 1.计算ob中有效node的个数\n",
    "        ob_len = torch.sum(torch.BoolTensor(torch.sum(self.node,-1)>0),-1)\n",
    "        ob_len_first = ob_len - atom_type_num\n",
    "        emb_node = self.mask_emb_len(emb_node, ob_len, 0)\n",
    "\n",
    "        ### 2.预测停止动作\n",
    "        emb_stop = F.relu(self.linear_stop1(emb_node))\n",
    "        self.logits_stop = torch.sum(emb_stop,1) #(B,1,f)\n",
    "        self.logits_stop = self.linear_stop2(self.logits_stop) #(B,1,2)\n",
    "        \n",
    "        # 分类分布中认为1是停止，但不能让它停止的过早，导致生成分子过简单 stop_shift一个负数\n",
    "        stop_shift = torch.Tensor([[0, stop_shift]])\n",
    "        pd_stop = D.Categorical(logits=self.logits_stop + stop_shift)\n",
    "        ac_stop = pd_stop.sample() #(B,1)\n",
    "        ac_stop = ac_stop.unsqueeze(-1)\n",
    "\n",
    "        ### 3.1 选第一个有效点(已在分子图中的)\n",
    "        self.logits_first = F.relu(self.linear_first1(emb_node)) #(B,n,f)\n",
    "        self.logits_first = self.linear_first2(emb_node).squeeze(-1) #(B,n)\n",
    "        # 保证选不到无效点\n",
    "        self.logits_first = self.logits_first.masked_fill(seq_range.expand(self.logits_first.shape)>=ob_len_first.expand(self.logits_first.shape),-10000)\n",
    "        pd_first = D.Categorical(logits=self.logits_first)\n",
    "        ac_first = pd_first.sample()\n",
    "        ac_first = ac_first.unsqueeze(-1) #(B,1)\n",
    "        # 只留选中结点的emb (B,f)\n",
    "        emb_first = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_first.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2)      \n",
    "        # 专家网络ground truth action\n",
    "        if self.ac_real.size>0:\n",
    "            ac_first_real = torch.Tensor(self.ac_real[:,0])\n",
    "            ac_first_real = ac_first_real.unsqueeze(-1)\n",
    "            emb_first_real = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_first_real.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2) \n",
    "\n",
    "        ### 3.2 选第二个点\n",
    "        emb_cat = torch.cat((emb_first.unsqueeze(-2).expand(emb_node.shape),emb_node), -1) #(B,n,2f)\n",
    "        self.logits_second = F.relu(self.linear_second1(emb_cat)) #(B,n,f)\n",
    "        self.logits_second = self.linear_second2(self.logits_second) #(B,n,1)\n",
    "        self.logits_second = self.logits_second.squeeze(-1)\n",
    "        self.logits_second = self.logits_second.masked_fill(ac_first.expand(self.logits_second.shape) == seq_range.unsqueeze(0).expand(self.logits_second.shape), -10000)\n",
    "        self.logits_second = self.logits_second.masked_fill(seq_range.expand(self.logits_second.shape)>=ob_len.expand(self.logits_second.shape),-10000)\n",
    "\n",
    "        pd_second = D.Categorical(logits=self.logits_second)\n",
    "        ac_second = pd_second.sample()\n",
    "        ac_second = ac_second.unsqueeze(-1)\n",
    "        # 只留选中结点的emb (B,f)\n",
    "        emb_second = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_second.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2) \n",
    "\n",
    "        # groundtruth\n",
    "        if self.ac_real.size>0:\n",
    "            emb_cat = torch.cat((emb_first_real.unsqueeze(-2).expand(emb_node.shape),emb_node), -1) #(B,n,2f)\n",
    "            self.logits_second_real = F.relu(self.linear_second1(emb_cat))\n",
    "            self.logits_second_real = self.linear_second2(self.logits_second_real).squeeze(-1)\n",
    "            ac_second_real = torch.Tensor(self.ac_real[:,1])\n",
    "            ac_second_real = ac_second_real.unsqueeze(-1)\n",
    "            emb_second_real = torch.sum(emb_node.masked_fill(seq_range.unsqueeze(-1).expand(emb_node.shape) != ac_second_real.squeeze(0).unsqueeze(-1).expand(emb_node.shape),0),-2)\n",
    "\n",
    "        ### 3.3 预测边类型\n",
    "        emb_cat = torch.cat((emb_first,emb_second),-1) #(B,2f)\n",
    "        self.logits_edge = F.relu(self.linear_edge1(emb_cat)) #(B,f)\n",
    "        self.logits_edge = self.linear_edge2(self.logits_edge) #(B,e)\n",
    "        pd_edge = D.Categorical(logits = self.logits_edge)\n",
    "        ac_edge = pd_edge.sample()\n",
    "        ac_edge = ac_edge.unsqueeze(-1)\n",
    "\n",
    "        #groundtruth\n",
    "        if self.ac_real.size>0:\n",
    "            emb_cat = torch.cat((emb_first_real, emb_second_real), -1)\n",
    "            self.logits_edge_real = F.relu(self.linear_edge1(emb_cat))\n",
    "            self.logits_edge_real = self.linear_edge2(self.logits_edge_real)\n",
    "        \n",
    "        ### 4. 预测状态价值\n",
    "        self.vpred = F.relu(self.value1(emb_node))\n",
    "        self.vpred = torch.max(self.vpred,1).values #(B,1,f)\n",
    "        self.vpred = self.value2(self.vpred)\n",
    "\n",
    "        self.ac = torch.cat((ac_first,ac_second,ac_edge,ac_stop),-1)\n",
    "        self.pd = None\n",
    "        if self.ac_real.size>0:\n",
    "            self.pd = {\"first\": D.Categorical(logits=self.logits_first), \"second\": D.Categorical(logits=self.logits_second_real), \n",
    "                        \"edge\": D.Categorical(logits=self.logits_edge_real), \"stop\": D.Categorical(logits=self.logits_stop)}\n",
    "            self.ac_real = np.array([])\n",
    "        return self.ac, self.vpred\n",
    "\n",
    "    def logp(self, ac):\n",
    "        ac = torch.LongTensor(ac)\n",
    "        if self.pd != None: \n",
    "            return self.pd[\"first\"].log_prob(ac[:,0]) + self.pd[\"second\"].log_prob(ac[:,1])\\\n",
    "                 + self.pd[\"edge\"].log_prob(ac[:,2]) + self.pd[\"stop\"].log_prob(ac[:,3])\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def entorpy(self):\n",
    "        result = None\n",
    "        if self.pd != None:\n",
    "            result =  self.pd[\"first\"].entropy() + self.pd[\"second\"].entropy()\\\n",
    "                 + self.pd[\"edge\"].entropy() + self.pd[\"stop\"].entropy()\n",
    "        return result\n",
    "\n",
    "    def kl(self, other_pd):\n",
    "        result = None\n",
    "        if self.pd != None and other_pd != None:\n",
    "            result = D.kl_divergence(self.pd[\"first\"], other_pd[\"first\"]) + D.kl_divergence(self.pd[\"second\"], other_pd[\"second\"])\\\n",
    "                + D.kl_divergence(self.pd[\"edge\"], other_pd[\"edge\"]) + D.kl_divergence(self.pd[\"stop\"], other_pd[\"stop\"])\n",
    "        return result\n",
    "    \n",
    "pi = GCNPolicy()\n",
    "old_pi = GCNPolicyold()\n",
    "\n",
    "for param_new, param_old in zip(pi.named_parameters(),old_pi.named_parameters()):\n",
    "    print(\"new:{new}, old:{old}\".format(new=param_new[0],old=param_old[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5226e-18, 2.5930e-09, 1.0299e-11, 7.7196e-10],\n",
       "         [1.0504e-05, 4.0974e-11, 1.0489e-08, 2.9571e-18],\n",
       "         [6.7333e+22, 1.7591e+22, 1.7184e+25, 4.3222e+27]],\n",
       "\n",
       "        [[6.1972e-04, 7.2443e+22, 1.7728e+28, 7.0367e+22],\n",
       "         [5.9018e-10, 2.1005e+20, 1.0188e-11, 6.7198e-07],\n",
       "         [1.3483e-05, 2.1234e+20, 1.2793e+22, 2.0429e+20]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor(2,3,4)\n",
    "a[0,:,:]\n",
    "a.masked_fill_(a<0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空间张力有效率：64.33767228177642%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./molecule_gen/atom_generate1.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    \n",
    "    num_count=0\n",
    "    invalid_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[9] == \"FALSE\":\n",
    "            invalid_count+=1\n",
    "print(\"空间张力有效率：{}%\".format((1-float(invalid_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空间张力有效率：98.13404638725804%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./molecule_gen/motif_expert_generate.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    \n",
    "    num_count=0\n",
    "    invalid_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[9] == \"FALSE\":\n",
    "            invalid_count+=1\n",
    "print(\"空间张力有效率：{}%\".format((1-float(invalid_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZINC规则有效率：91.29977029096477%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./molecule_gen/atom_generate1.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    \n",
    "    num_count=0\n",
    "    invalid_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[10] == \"FALSE\":\n",
    "            invalid_count+=1\n",
    "print(\"ZINC规则有效率：{}%\".format((1-float(invalid_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZINC规则有效率：100.0%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./molecule_gen/motif_expert_generate.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    \n",
    "    num_count=0\n",
    "    invalid_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[10] == \"FALSE\":\n",
    "            invalid_count+=1\n",
    "print(\"ZINC规则有效率：{}%\".format((1-float(invalid_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZINC规则有效率：99.29663430796954%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./molecule_gen/motif_expert_generate.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    \n",
    "    num_count=0\n",
    "    invalid_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[10] == \"FALSE\":\n",
    "            invalid_count+=1\n",
    "print(\"ZINC规则有效率：{}%\".format((1-float(invalid_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成分子较MOSES新颖率：100.0%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "MOSES_smiles = []\n",
    "with open('./molecule_gen/all.txt',\"r\") as f:\n",
    "    while True:\n",
    "        smiles = f.readline()\n",
    "        if not smiles:\n",
    "            break\n",
    "        MOSES_smiles.append(smiles)\n",
    "with open('./molecule_gen/motif_expert_generate.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    num_count=0\n",
    "    innovel_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[0] in MOSES_smiles:\n",
    "            innovel_count+=1\n",
    "print(\"生成分子较MOSES新颖率：{}%\".format((1-float(innovel_count)/num_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Geometry\n",
    "from rdkit.Geometry import rdGeometry\n",
    "\n",
    "motif_molset = []\n",
    "with open('./molecule_gen/motif_expert_generate.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    num_count=0\n",
    "    innovel_count=0\n",
    "    for row in spamreader:\n",
    "        num_count+=1\n",
    "        if row[0] not in motif_molset:\n",
    "            motif_molset.append(row[0])\n",
    "dis_arr = []\n",
    "for smiles in motif_molset:\n",
    "    idx = motif_molset.index(smiles)\n",
    "    for i in range(len(motif_molset)):\n",
    "        if i != idx:\n",
    "            m1 = Chem.MolFromSmiles(smiles)\n",
    "            m2 = Chem.MolFromSmiles(motif_molset[i])\n",
    "            bv1 = AllChem.GetMorganFingerprintAsBitVect(m1, 2, nBits=1024)\n",
    "            bv2 = AllChem.GetMorganFingerprintAsBitVect(m2, 2, nBits=1024)\n",
    "            dis_arr.append(1-cDataStructs.TanimotoSimilarity(bv1,bv2))\n",
    "dis_arr = np.array(dis_arr)\n",
    "print(\"生成分子的diversity为： \",np.mean(dis_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import cDataStructs\n",
    "import numpy as np\n",
    "\n",
    "m1 = Chem.MolFromSmiles(\"CCC(NC(=O)c1scnc1C1CC1)C(=O)N1CCOCC1\")\n",
    "m2 = Chem.MolFromSmiles(\"O=C1OCCC1Sc1nnc(-c2c[nH]c3ccccc23)n1C1CC1\")\n",
    "\n",
    "dis = [2,2,2,2,2]\n",
    "dis = np.array(dis)\n",
    "np.mean(dis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
